{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "# Import metrics for comparing approaches\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Jupyter Notebook inline graph fix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\JackC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JackC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\JackC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JackC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\JackC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\JackC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Data\n",
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetId</th>\n",
       "      <th>tweetText</th>\n",
       "      <th>userId</th>\n",
       "      <th>imageId(s)</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>263046056240115712</td>\n",
       "      <td>¬øSe acuerdan de la pel√≠cula: ‚ÄúEl d√≠a despu√©s de ma√±ana‚Äù? Me recuerda a lo que est√° pasando con el hurac√°n #Sandy. http://t.co/JQQeRPwN</td>\n",
       "      <td>21226711</td>\n",
       "      <td>sandyA_fake_46</td>\n",
       "      <td>iAnnieM</td>\n",
       "      <td>Mon Oct 29 22:34:01 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>262995061304852481</td>\n",
       "      <td>@milenagimon: Miren a Sandy en NY!  Tremenda imagen del hurac√°n. Parece el \"D√≠a de la Independencia 2\" http://t.co/41jUweux REAL! RT.</td>\n",
       "      <td>192378571</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>CarlosVerareal</td>\n",
       "      <td>Mon Oct 29 19:11:23 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>262979898002534400</td>\n",
       "      <td>Buena la foto del Hurac√°n Sandy, me recuerda a la pel√≠cula D√≠a de la Independencia #ID4 #Sandy  http://t.co/PTdAXABZ</td>\n",
       "      <td>132303095</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>LucasPalape</td>\n",
       "      <td>Mon Oct 29 18:11:08 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>262996108400271360</td>\n",
       "      <td>Scary shit #hurricane #NY http://t.co/e4JLBUfH</td>\n",
       "      <td>241995902</td>\n",
       "      <td>sandyA_fake_29</td>\n",
       "      <td>Haaaaarryyy</td>\n",
       "      <td>Mon Oct 29 19:15:33 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>263018881839411200</td>\n",
       "      <td>My fave place in the world #nyc #hurricane #sandy #statueofliberty üóΩ http://t.co/Ex61doZk</td>\n",
       "      <td>250315890</td>\n",
       "      <td>sandyA_fake_15</td>\n",
       "      <td>princess__natt</td>\n",
       "      <td>Mon Oct 29 20:46:02 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetId  \\\n",
       "0  263046056240115712   \n",
       "1  262995061304852481   \n",
       "2  262979898002534400   \n",
       "3  262996108400271360   \n",
       "4  263018881839411200   \n",
       "\n",
       "                                                                                                                                tweetText  \\\n",
       "0  ¬øSe acuerdan de la pel√≠cula: ‚ÄúEl d√≠a despu√©s de ma√±ana‚Äù? Me recuerda a lo que est√° pasando con el hurac√°n #Sandy. http://t.co/JQQeRPwN   \n",
       "1  @milenagimon: Miren a Sandy en NY!  Tremenda imagen del hurac√°n. Parece el \"D√≠a de la Independencia 2\" http://t.co/41jUweux REAL! RT.    \n",
       "2  Buena la foto del Hurac√°n Sandy, me recuerda a la pel√≠cula D√≠a de la Independencia #ID4 #Sandy  http://t.co/PTdAXABZ                     \n",
       "3  Scary shit #hurricane #NY http://t.co/e4JLBUfH                                                                                           \n",
       "4  My fave place in the world #nyc #hurricane #sandy #statueofliberty üóΩ http://t.co/Ex61doZk                                                \n",
       "\n",
       "      userId      imageId(s)        username                       timestamp  \\\n",
       "0  21226711   sandyA_fake_46  iAnnieM         Mon Oct 29 22:34:01 +0000 2012   \n",
       "1  192378571  sandyA_fake_09  CarlosVerareal  Mon Oct 29 19:11:23 +0000 2012   \n",
       "2  132303095  sandyA_fake_09  LucasPalape     Mon Oct 29 18:11:08 +0000 2012   \n",
       "3  241995902  sandyA_fake_29  Haaaaarryyy     Mon Oct 29 19:15:33 +0000 2012   \n",
       "4  250315890  sandyA_fake_15  princess__natt  Mon Oct 29 20:46:02 +0000 2012   \n",
       "\n",
       "  label  \n",
       "0  fake  \n",
       "1  fake  \n",
       "2  fake  \n",
       "3  fake  \n",
       "4  fake  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14483 entries, 0 to 14482\n",
      "Data columns (total 7 columns):\n",
      "tweetId       14483 non-null int64\n",
      "tweetText     14483 non-null object\n",
      "userId        14483 non-null int64\n",
      "imageId(s)    14483 non-null object\n",
      "username      14483 non-null object\n",
      "timestamp     14483 non-null object\n",
      "label         14483 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 792.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fake     6841\n",
       "real     5009\n",
       "humor    2633\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv('mediaeval-2015-trainingset.txt', sep='\\\\t', engine='python', encoding='utf-8')\n",
    "\n",
    "display(train_data.head())\n",
    "display(train_data.info())\n",
    "display(train_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetId</th>\n",
       "      <th>tweetText</th>\n",
       "      <th>userId</th>\n",
       "      <th>imageId(s)</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>578854927457349632</td>\n",
       "      <td>kereeen RT @Shyman33: Eclipse from ISS.... http://t.co/je2hcFpVfN</td>\n",
       "      <td>70824972</td>\n",
       "      <td>eclipse_01</td>\n",
       "      <td>peay_s</td>\n",
       "      <td>Fri Mar 20 09:45:43 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>578874632670953472</td>\n",
       "      <td>Absolutely beautiful! RT @Shyman33: Eclipse from ISS.... http://t.co/oqwtTL0ThS</td>\n",
       "      <td>344707006</td>\n",
       "      <td>eclipse_01</td>\n",
       "      <td>JaredUcanChange</td>\n",
       "      <td>Fri Mar 20 11:04:02 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>578891261353984000</td>\n",
       "      <td>‚Äú@Shyman33: Eclipse from ISS.... http://t.co/C0VfboScRj‚Äù Ïö∞Ï£ºÏóêÏÑúÎ≥∏ 3.20 ÏùºÏãù Wow! amazing!</td>\n",
       "      <td>224839607</td>\n",
       "      <td>eclipse_01</td>\n",
       "      <td>tpjp1231</td>\n",
       "      <td>Fri Mar 20 12:10:06 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>578846612312748032</td>\n",
       "      <td>Eclipse from ISS.... http://t.co/En87OtvsU6</td>\n",
       "      <td>134543073</td>\n",
       "      <td>eclipse_01</td>\n",
       "      <td>Shyman33</td>\n",
       "      <td>Fri Mar 20 09:12:41 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>578975333841551360</td>\n",
       "      <td>\"@ebonfigli: √âclipse vue de l'ISS... Autre chose... http://t.co/yNBN7c4O51\"\\n\\nLa cr√©ation divine n'a pas de limite üòç</td>\n",
       "      <td>1150728872</td>\n",
       "      <td>eclipse_01</td>\n",
       "      <td>Epimethee_</td>\n",
       "      <td>Fri Mar 20 17:44:11 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetId  \\\n",
       "0  578854927457349632   \n",
       "1  578874632670953472   \n",
       "2  578891261353984000   \n",
       "3  578846612312748032   \n",
       "4  578975333841551360   \n",
       "\n",
       "                                                                                                               tweetText  \\\n",
       "0  kereeen RT @Shyman33: Eclipse from ISS.... http://t.co/je2hcFpVfN                                                       \n",
       "1  Absolutely beautiful! RT @Shyman33: Eclipse from ISS.... http://t.co/oqwtTL0ThS                                         \n",
       "2  ‚Äú@Shyman33: Eclipse from ISS.... http://t.co/C0VfboScRj‚Äù Ïö∞Ï£ºÏóêÏÑúÎ≥∏ 3.20 ÏùºÏãù Wow! amazing!                                    \n",
       "3  Eclipse from ISS.... http://t.co/En87OtvsU6                                                                             \n",
       "4  \"@ebonfigli: √âclipse vue de l'ISS... Autre chose... http://t.co/yNBN7c4O51\"\\n\\nLa cr√©ation divine n'a pas de limite üòç   \n",
       "\n",
       "       userId   imageId(s)         username                       timestamp  \\\n",
       "0  70824972    eclipse_01   peay_s           Fri Mar 20 09:45:43 +0000 2015   \n",
       "1  344707006   eclipse_01   JaredUcanChange  Fri Mar 20 11:04:02 +0000 2015   \n",
       "2  224839607   eclipse_01   tpjp1231         Fri Mar 20 12:10:06 +0000 2015   \n",
       "3  134543073   eclipse_01   Shyman33         Fri Mar 20 09:12:41 +0000 2015   \n",
       "4  1150728872  eclipse_01   Epimethee_       Fri Mar 20 17:44:11 +0000 2015   \n",
       "\n",
       "  label  \n",
       "0  fake  \n",
       "1  fake  \n",
       "2  fake  \n",
       "3  fake  \n",
       "4  fake  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3781 entries, 0 to 3780\n",
      "Data columns (total 7 columns):\n",
      "tweetId       3781 non-null int64\n",
      "tweetText     3781 non-null object\n",
      "userId        3781 non-null int64\n",
      "imageId(s)    3781 non-null object\n",
      "username      3781 non-null object\n",
      "timestamp     3781 non-null object\n",
      "label         3781 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 206.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fake    2564\n",
       "real    1217\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = pd.read_csv('mediaeval-2015-testset.txt', sep='\\\\t', engine='python', encoding='utf-8')\n",
    "\n",
    "display(test_data.head())\n",
    "display(test_data.info())\n",
    "display(test_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_data['label']).set_title(\"Training Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake    9474\n",
       "real    5009\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the humor labels with fake\n",
    "train_data['label'].replace(\"humor\", \"fake\", inplace=True)\n",
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_data['label']).set_title(\"Training Dataset (humor converted to fake)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(test_data['label']).set_title(\"Test Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Text\n",
    "\n",
    "### All Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the tweetText and label column from the training data - label is required to break up based on real/fake\n",
    "length = train_data[['tweetText', 'label']].copy()\n",
    "\n",
    "# Calculate the length of each tweet (this is before any pre processing) and add it as a column\n",
    "length['length'] = length['tweetText'].str.len()\n",
    "\n",
    "def plotLengths(data, title) :\n",
    "    plt.clf()\n",
    "    sns.distplot(data['length'], hist=True, kde=False, vertical=True, bins=100).set_title(title)\n",
    "    # Limit the length axis to remove any anomalous results (due to character encoding)\n",
    "    plt.ylim(0, 150)\n",
    "    plt.show()\n",
    "    \n",
    "plotLengths(length, \"All Tweet Lengths Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLengths(length.loc[length['label'] == \"fake\"], \"Fake Tweet Lengths Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLengths(length.loc[length['label'] == \"real\"], \"Real Tweet Lengths Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tweetText and convert the labels to binary\n",
    "def injestData(old, train) :\n",
    "    # Extract only the tweetText and label\n",
    "    new = old[['tweetText', 'label']].copy()\n",
    "    \n",
    "    # Convert the text labels to numeric\n",
    "    new['label'] = new.label.eq('fake').mul(1)\n",
    "    \n",
    "    # Remove noise from the training data\n",
    "    if train :\n",
    "        # Remove duplicate tweetText\n",
    "        new.drop_duplicates(subset='tweetText', keep='first', inplace=True)\n",
    "\n",
    "        # Remove direct retweets (tweets that start with RT)\n",
    "        new = new[~new.tweetText.str.startswith('RT')]\n",
    "\n",
    "        # Reset the index after dropping rows\n",
    "        new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return new\n",
    "\n",
    "train = injestData(train_data, True)\n",
    "test = injestData(test_data, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>se acuerdan de la pelcula el da despus de maana me recuerda lo que est pasando con el huracn sandy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>miren sandy en ny tremenda imagen del huracn parece el da de la independencia 2 real rt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>buena la foto del huracn sandy me recuerda la pelcula da de la independencia id4 sandy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>scary shit hurricane ny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>my fave place in the world nyc hurricane sandy statueofliberty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            tweetText  \\\n",
       "0  se acuerdan de la pelcula el da despus de maana me recuerda lo que est pasando con el huracn sandy   \n",
       "1  miren sandy en ny tremenda imagen del huracn parece el da de la independencia 2 real rt              \n",
       "2  buena la foto del huracn sandy me recuerda la pelcula da de la independencia id4 sandy               \n",
       "3  scary shit hurricane ny                                                                              \n",
       "4  my fave place in the world nyc hurricane sandy statueofliberty                                       \n",
       "\n",
       "   label  \n",
       "0  1      \n",
       "1  1      \n",
       "2  1      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>kereeen rt eclipse from i</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>absolutely beautiful rt eclipse from i</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>eclipse from i 3 20 wow amazing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>eclipse from i</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>clipse vue de i autre chose cration divine a pa de limite</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweetText  label\n",
       "0  kereeen rt eclipse from i                                  1    \n",
       "1  absolutely beautiful rt eclipse from i                     1    \n",
       "2  eclipse from i 3 20 wow amazing                            1    \n",
       "3  eclipse from i                                             1    \n",
       "4  clipse vue de i autre chose cration divine a pa de limite  1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean the tweetText\n",
    "def cleanText(data) :\n",
    "    tweets = []\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    \n",
    "    for t in range(0, len(data)) :\n",
    "        # Remove URLs\n",
    "        tweet = re.sub(r'https?://[^\\s]+', '', str(data[t]))\n",
    "\n",
    "        # Remove mentions\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "        # Remove hashtags\n",
    "        # tweet = re.sub(r'#\\w+', '', tweet)\n",
    "        \n",
    "        # Remove non-english characters\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
    "        \n",
    "        # Remove all the special characters\n",
    "        tweet = re.sub(r'\\W', ' ', tweet)\n",
    "        \n",
    "        # Remove all single characters\n",
    "        tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', tweet)\n",
    "        \n",
    "        # Remove single characters from the start\n",
    "        tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', tweet)\n",
    "    \n",
    "        # Substituting multiple spaces with a single space\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet, flags=re.I)\n",
    "\n",
    "        # Convert to lower case\n",
    "        tweet = tweet.lower()\n",
    "\n",
    "        # Lemmatisation\n",
    "        tweet = tweet.split()\n",
    "        \n",
    "        tweet = [stemmer.lemmatize(word) for word in tweet]\n",
    "        tweet = ' '.join(tweet)\n",
    "        \n",
    "        tweets.append(tweet)\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "# Clean the tweet text content for the training and test data\n",
    "train['tweetText'] = cleanText(train['tweetText'])\n",
    "test['tweetText'] = cleanText(test['tweetText'])\n",
    "\n",
    "# Prevent pandas from truncating the data so we can confirm the URL's are removed\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency (For Visualisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWordFrequency (data, title) : \n",
    "    all_words_list = []\n",
    "    for tweet in data :\n",
    "        all_words_list.append(nltk.tokenize.word_tokenize(tweet))\n",
    "\n",
    "    all_words = [i for j in all_words_list for i in j]\n",
    "\n",
    "    # Remove words that are specific to events which aren't helpful in spotting patterns\n",
    "    event_words = ['sandy', 'hurricane', 'hurricanesandy', 'new', 'nyc', 'ny', 'york', 'statue', 'statueofliberty', \n",
    "                   'shark', 'newyork', 'tomb', 'sochi', 'soldier', 'liberty', 'jersey', 'nj', 'mh370', 'hurac√°n', \n",
    "                   'boston', 'manhattan', 'bringbackourgirls', 'columbianchemicals', 'flooding', 'flood', 'cuba']\n",
    "    platform_words = ['rt']\n",
    "    en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "    sp_stop_words = nltk.corpus.stopwords.words('spanish')\n",
    "    block_words = en_stop_words + sp_stop_words + event_words + platform_words\n",
    "\n",
    "    fd = nltk.FreqDist(w.lower() for w in all_words if w not in block_words)\n",
    "    fd_top = fd.most_common(20)\n",
    "    fd.plot(30, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotWordFrequency(train['tweetText'].loc[train['label'] == 1], \"Most Common Words in Fake Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotWordFrequency(train['tweetText'].loc[train['label'] == 0], \"Most Common Words in Real Tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise the tweetText\n",
    "def tokenize(data) :\n",
    "    return data.apply(nltk.tokenize.word_tokenize)\n",
    "\n",
    "train_tokens = tokenize(train['tweetText'])\n",
    "test_tokens = tokenize(test['tweetText'])\n",
    "\n",
    "display(train_tokens[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tag the tokenized text\n",
    "def pos(data) :\n",
    "    return data.apply(nltk.tag.pos_tag)\n",
    "\n",
    "train_pos = pos(train_tokens)\n",
    "test_pos = pos(train_tokens)\n",
    "\n",
    "display(train_pos[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [(I, PRP), (am, VBP), (in, IN), (new, JJ), (york, NN), (and, CC), (hurricanesandy, NN), (is, VBZ), (kicking, VBG), (off, RP)]\n",
      "Name: tweetText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# NER tagging the POS text - ineffective\n",
    "def ner(data) :\n",
    "    return data.apply(nltk.ne_chunk)\n",
    "\n",
    "train_ner = ner(train_pos)\n",
    "test_ner = ner(test_pos)\n",
    "\n",
    "display(train_ner[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n-grams\n",
    "list_ngram = list(ngrams(sequence = s, n = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes stop words - test using Spanish ones as well\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X_train = tfidfconverter.fit_transform(train['tweetText']).toarray()\n",
    "X_test = tfidfconverter.transform(test['tweetText']).toarray()\n",
    "\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
